---
title: "Case Study: How Does a Bike-Share Navigate Speedy Success?"
author: "Laura Fontanills"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Required Packages, include=FALSE}
library(kableExtra) 
library(tidyverse)
library(lubridate)
```


### 0.1 Purpose

In this document I will import, clean, and analyze 12 months of bike-share user data. My task is to analyze ride data to determine how annual members and casual riders use the bike-share differently. This analysis will guide my recommendations for marketing strategy to convert casual riders into annual members. I completed this case study as part of my Google Data Analytics Certification. 

The case study is about a fictional bike-share company called Cyclistic, while the data is taken from Chicago's Divvy bike-share, so I will describe some considerations and assumptions I made to reconcile the case and the data set. 

### 0.2 Considerations

#### Comparing Cyclistic (fictional) and Divvy (real)

```{r comparison_table, echo=FALSE}

comparison_table <- tibble(
  Item = c("Member types", "Bike types", "Docking", "Pricing"),
  Cyclistic = c("Member, Casual", "Classic, E-bike, Accessible bikes", "Must be docked", "Unspecified"),
  Divvy = c("Member, Casual", "Classic, E-Bike, Docked bike", "Docked, undocked with fees", "Flat rates with fees")
)

comparison_table %>% 
  kbl() %>% 
  kable_material(c("striped"))
```
#### Initial Assumptions

* Bike types: Since Cyclistic's accessible bikes account for 8% of riders, and Divvy does not have accessible bikes, I consider only classic and e-bikes in my analysis.

* Docking: Divvy docks use a different geolocation system than the bikes themselves-- docks have geolocation with 0.000001° sensitivity, while undocked bikes have geolocation with 0.01° sensitivity. Many Divvy docks are within 0.01° of other docks, especially in the city center where most rides take place, so undocked bikes can't reliably be matched with nearby docks. As Cyclistic bikes must all be docked, I am considering only bikes that start and end at docks in my analysis.


### 0.2 Import and Preview the Data sets

Divvy ride data sets ar available here:
[Monthly data sets](https://divvy-tripdata.s3.amazonaws.com/index.html)
[License](https://www.divvybikes.com/data-license-agreement)

I used R to clean and analyze these data sets. They are very large data sets, some of which contain millions of data points.  

```{r Import and preview, include=FALSE}
# change wd to access csv files
setwd("/Users/laurafontanills/Documents/datasets/divvy_csv_monthly")

# import csv files as data frames
rides_202201 <- read.csv("202201-divvy-tripdata.csv") # January 2022
rides_202202 <- read.csv("202202-divvy-tripdata.csv") # February 2022
rides_202203 <- read.csv("202203-divvy-tripdata.csv") # March 2022
rides_202204 <- read.csv("202204-divvy-tripdata.csv") # April 2022
rides_202205 <- read.csv("202205-divvy-tripdata.csv") # May 2022
rides_202206 <- read.csv("202206-divvy-tripdata.csv") # June 2022
rides_202207 <- read.csv("202207-divvy-tripdata.csv") # July 2022
rides_202208 <- read.csv("202208-divvy-tripdata.csv") # August 2022
rides_202209 <- read.csv("202209-divvy-publictripdata.csv") # September 2022
rides_202210 <- read.csv("202210-divvy-tripdata.csv") # October 2022
rides_202211 <- read.csv("202211-divvy-tripdata.csv") # November 2022
rides_202212 <- read.csv("202212-divvy-tripdata.csv") # December 2022

# change wd to project folder
setwd("/Users/laurafontanills/Documents/projects/bikeshare-case-study")
```

Preview: January 2022 (uncomment to view other months)
```{r Preview January, echo=TRUE}
rides_202201 #January 2022
# rides_202202 # February 2022
# rides_202203 # March 2022
# rides_202204 # April 2022
# rides_202205 # May 2022
# rides_202206 # June 2022
# rides_202207 # July 2022
# rides_202208 # August 2022
# rides_202209 # September 2022
# rides_202210 # October 2022
# rides_202211 # November 2022
# rides_202212 # December 2022

```

Each monthly data set contains 13 columns. The data is normalized.
* ride_id (a unique code for individual trips)
* rideable_type (bike type)
* started_at (start date and time)
* ended_at (end date and time)
* start_station_name (starting docking station, if applicable)
* end_station_name (ending docking station, if applicable)
* start_station_id (a unique code for each docking station)
* end_station_id (a unique code for each docking station)
* start_lat (geolocation for starting point)
* start_lng (geolocation for starting point)
* end_lat (geolocation for ending point)
* end_lng (geolocation for ending point)
* member_casual (member type)


### 1.1 Data preprocessing and transformation

First, I verified each of the 12 data sets individually. For each month I checked the following:
* Are all ride IDs unique?
* Are there only 3 rideable types (classic, e-bike, docked)?
* Do rides start in the correct month?
* Are all geolocations in the Chicago area?
* Are there only 2 member types (member, casual)?

Then, I located rides that I would filter out later -- those with no start or end location data, no end time, rides on "docked" bike types.

Then, I created new columns for ride length (in seconds), start date, start time, start month, and start weekday, as I wanted to analyze these later. 

Finally I created a new data frame with filtered monthly data.

In this section, I've included more detail about January, March, and November, which had invalid data points.

#### January 2022 Review - 1 Ride outside the Chicago area

Here is how I reviewed January's data frame rides_202201:

```{r}
# Inspect January data frame columns
str(rides_202201) # see started_at, ended_at are chars, not datetime
```

Started_at and ended_at are the wrong data type: I created two new columns in which I transformed started_at and ended_at into datetime format.

```{r}
# create columns with starting, ending ride datetimes
rides_202201$start_datetime <- ymd_hms(rides_202201$started_at)
rides_202201$end_datetime <- ymd_hms(rides_202201$ended_at)
```

I verified January's data:

```{r}
# inspect January data frame
summary(rides_202201)

# check all ride IDs are unique
rides_202201 %>% 
  group_by (ride_id) %>% 
  summarize (ride_id)
```

From the summary, I see that the maximum start_lng is -73.80, which is outside the Chicago area. Further inspection shows 1 test ride that I will filter out later.

```{r}
# locate rows with rides not in Chicago area
rides_202201 %>% 
  filter(start_lng > -86)
```

I previewed the data I would filter out later on.

```{r}
# locate rides with no geolocation
rides_202201 %>% 
  filter(is.na(start_lat) | is.na(start_lng) | is.na(end_lat) | is.na(end_lng))

# locate rides with no docking stations
rides_202201 %>% 
  filter(start_station_id == "" | end_station_id == "")
```

I created new columns for ride length (in seconds), start date, start time, start month, and start weekday.

```{r}
# create column ride_length (in seconds) as numeric 
rides_202201$ride_length <- as.numeric(rides_202201$end_datetime - rides_202201$start_datetime)

# create columns for start date only, start time only, start month only 
rides_202201$ride_date <- as.Date(rides_202201$start_datetime) # Date format
rides_202201$ride_hour <- hour(rides_202201$start_datetime) # integer
rides_202201$ride_month <- month(rides_202201$start_datetime, label = TRUE)
rides_202201$ride_weekday <- wday(rides_202201$start_datetime, label = TRUE)
```

After calculating ride length, I verified the data again, to check that ride lengths were all positive.
```{r}
summary(rides_202201)
```

I previewed the ride duration data that I wanted to filter out; I only considered rides with duration between 60 seconds and 24 hours, to account for rides where the docks did not work properly, where bikes were immediately returned, or rides where the user took the bike and didn't return it within a day.

```{r}
# locate rides with ride_length < 60 seconds or ride_length > 86400 seconds
rides_202201 %>% 
  filter(ride_length < 60 | ride_length > 86400)
```
Finally I created a new, filtered data frame and cleaned up my environment.

```{r}
# create new data frame with cleaned January data
rides_202201_v2 <- rides_202201[
  (!is.na(rides_202201$start_lat) | !is.na(rides_202201$start_lng) # no start geolocation
   | !is.na(rides_202201$end_lat) | !is.na(rides_202201$end_lng) # no end geolocation
   | rides_202201$start_station_name != "" | rides_202201$end_station_name != "" # no dock station
   |  !(rides_202201$start_lat > -86) # not in Chicago
   | !(rides_202201$ride_length < 60) # too short
   | !(rides_202201$ride_length > 86400) # too long
   | rides_202201$rideable_type != "docked_bike") # unspecified bike type
  ,]


# remove started_at, ended_at columns
rides_202201_v2 <- 
  rides_202201_v2 %>% 
 select(-c(started_at, ended_at))

# remove old df
rm(rides_202201)
```


#### March 2022 - DST 

